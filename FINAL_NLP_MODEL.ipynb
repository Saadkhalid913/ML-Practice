{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImprovedNLPModel.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOYpjUTzLu5DkWTKzdPA51F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saadkhalid913/ML-Practice/blob/main/FINAL_NLP_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EiXkr2BrX5h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a051d3ed-2b63-47a3-cad5-4212e39d6dd3"
      },
      "source": [
        "import nltk \n",
        "from nltk.stem import wordnet, WordNetLemmatizer\n",
        "import re \n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "EnglishStopwords = nltk.corpus.stopwords.words(\"english\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AB70vL7ztYT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3LwdX6Xgxlpp",
        "outputId": "29c94cb3-a79a-46d7-e746-aaacfd935fd1"
      },
      "source": [
        "data = pd.read_csv(\"train.txt\", sep = \";\", header=None)\n",
        "x = data.iloc[ : , : -1].values\n",
        "y = data.iloc[ : , -1 : ].values\n",
        "\n",
        "trainX, testX, trainY, testY = train_test_split(x,y, test_size=0.1)\n",
        "\n",
        "print(trainX.shape)\n",
        "print(trainY.shape)\n",
        "print(testX.shape)\n",
        "print(testY.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(14400, 1)\n",
            "(14400, 1)\n",
            "(1600, 1)\n",
            "(1600, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oaLEFsyy6Dn"
      },
      "source": [
        "def CleanFeatures(features):\n",
        "  '''\n",
        "    takes 2D numpy array of text data and \n",
        "    removes stopwords, non-alphanumeric characters,\n",
        "    trailing whitespaces, and applies lemmatization \n",
        "  '''\n",
        "\n",
        "  lemma = WordNetLemmatizer()\n",
        "  sentences = features.flatten()\n",
        "  cleaned = []\n",
        "  for sentence in sentences:\n",
        "      sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n",
        "      sentence = sentence.lower()\n",
        "      sentence = sentence.split()\n",
        "      sentence = [lemma.lemmatize(word) for word in sentence if word not in set(EnglishStopwords)]\n",
        "      sentence = \" \".join(sentence)\n",
        "      cleaned.append(sentence)\n",
        "\n",
        "  \n",
        "  return cleaned \n",
        "\n",
        "trainX = CleanFeatures(trainX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jW0fSLtW3rRB"
      },
      "source": [
        "def Tokenize(sentences):\n",
        "  ''' \n",
        "    Takes a 1D string of sentences and tokenizes them\n",
        "    with 150 tokens by default\n",
        "  '''\n",
        "  tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
        "  tokenizer.fit_on_texts(sentences)\n",
        "  sequences = tokenizer.texts_to_sequences(sentences)\n",
        "  sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen = 150, dtype='int32')\n",
        "  return sequences, tokenizer\n",
        "def TokenizeTestData(testData, tokenizerObject):\n",
        "  '''\n",
        "    testData: 1D array of sentences\n",
        "  '''\n",
        "  sequences = tokenizerObject.texts_to_sequences(testData)\n",
        "  return tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen = 150, dtype='int32')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHoZUdalDxHd"
      },
      "source": [
        "trainX , tokenizer = Tokenize(trainX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSElusmxnq9O"
      },
      "source": [
        "num_words = len(tokenizer.index_word) + 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HILSwAabCWPf"
      },
      "source": [
        "encoder = OneHotEncoder()\n",
        "trainY = encoder.fit_transform(trainY).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjV8ZoWtBGiX"
      },
      "source": [
        "def CreateModel():\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Embedding(num_words, 240, input_length=150))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "  model.add(tf.keras.layers.Dense(units = 64, activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dropout(rate = 0.15))\n",
        "  model.add(tf.keras.layers.Dense(units = 48, activation=\"relu\"))\n",
        "  model.add(tf.keras.layers.Dense(units = 6, activation=\"softmax\"))\n",
        "  model.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "  return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKnQQ3pBDIgf",
        "outputId": "4bfc4341-10f9-41e8-e3ef-98c57ab82449"
      },
      "source": [
        "ann2 = CreateModel()\n",
        "ann2.summary()\n",
        "ann2.fit(trainX, trainY, epochs = 5, batch_size = 64)\n",
        "ann2.save_weights(\"test\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 150, 240)          3063840   \n",
            "                                                                 \n",
            " flatten_5 (Flatten)         (None, 36000)             0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 64)                2304064   \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_16 (Dense)            (None, 48)                3120      \n",
            "                                                                 \n",
            " dense_17 (Dense)            (None, 6)                 294       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,371,318\n",
            "Trainable params: 5,371,318\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "225/225 [==============================] - 16s 71ms/step - loss: 1.5054 - accuracy: 0.3808\n",
            "Epoch 2/5\n",
            "225/225 [==============================] - 16s 71ms/step - loss: 0.6953 - accuracy: 0.7433\n",
            "Epoch 3/5\n",
            "225/225 [==============================] - 16s 71ms/step - loss: 0.2835 - accuracy: 0.9068\n",
            "Epoch 4/5\n",
            "225/225 [==============================] - 16s 70ms/step - loss: 0.1434 - accuracy: 0.9572\n",
            "Epoch 5/5\n",
            "225/225 [==============================] - 16s 71ms/step - loss: 0.0790 - accuracy: 0.9782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aaf7ulzQQqgj"
      },
      "source": [
        "testX = CleanFeatures(testX)\n",
        "testX = TokenizeTestData(testX, tokenizer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKe-USc6NNj0"
      },
      "source": [
        "testY = encoder.transform(testY).toarray()\n",
        "np.array(testY).shape\n",
        "np.array(testX).shape\n",
        "result = ann2.predict(testX)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3lWlzxDQIeO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d78d78fa-f744-4b49-b548-0f5439132614"
      },
      "source": [
        "# y_acc = encoder.transform(testY)\n",
        "y_truth = np.argmax(testY, axis = 1)\n",
        "y_preds = np.argmax(result, axis = 1)\n",
        "\n",
        "correct_preds = y_preds == y_truth \n",
        "print(np.sum(correct_preds) / 1600)\n",
        "\n",
        "# print(correct_preds)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.838125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFwiVmnpLD28"
      },
      "source": [
        "def MakePred(s):\n",
        "  s = CleanFeatures(np.array([[s]]))\n",
        "  s = TokenizeTestData(s, tokenizer)\n",
        "  result = ann2.predict(s)\n",
        "  emotions = [\"anger\", \"fear\", \"joy\", \"love\", \"sadness\", \"surprise\"]\n",
        "  final = np.argmax(result, axis = 1)[0]\n",
        "  final = emotions[final]\n",
        "  # result = list(map(float, result))\n",
        "  # final = { emotions[i]: result[i] for i in range(6)}\n",
        "  return final\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZQsoI4ByC9C",
        "outputId": "9c1ce015-9dde-40ba-a865-1b3842cf81a6"
      },
      "source": [
        "## PRED PIPELINE \n",
        "\n",
        "preds = [\n",
        "         \"I had a horrible day today\",\n",
        "         \"thats crazy bro\",\n",
        "         \"i am not having a good time rn, im so sad\",\n",
        "         \"i need to work harder\",\n",
        "         \"im having the best day ever\",\n",
        "         \"evan is such a great guy\",\n",
        "         \"i wish that I had the courage to read more\",\n",
        "         \"i wish I believed in myself\",\n",
        "         \"im scared\",\n",
        "         \"I wish that I could be born in a world where justice was upheld. I wish I could live in a world where I feel the need to prove my worth\"\n",
        "]\n",
        "\n",
        "for sen in preds:\n",
        "  result = MakePred(sen)\n",
        "  print(f\"{sen} -- {result}\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I had a horrible day today -- sadness\n",
            "thats crazy bro -- sadness\n",
            "i am not having a good time rn, im so sad -- sadness\n",
            "i need to work harder -- sadness\n",
            "im having the best day ever -- joy\n",
            "evan is such a great guy -- joy\n",
            "i wish that I had the courage to read more -- sadness\n",
            "i wish I believed in myself -- fear\n",
            "im scared -- fear\n",
            "I wish that I could be born in a world where justice was upheld. I wish I could live in a world where I feel the need to prove my worth -- joy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnWfQmH73l6O"
      },
      "source": [
        "import pickle \n",
        "with open(\"tokenizer.pkl\", \"wb\") as f:\n",
        "  f.write(pickle.dumps(tokenizer))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuFbI_vD3l0O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c9e1f1d-070b-4414-d7ea-4c988bed8adc"
      },
      "source": [
        "arr = np.array([[1,1],[2,2]])\n",
        "\n",
        "np.sum(arr, axis = 0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZrJZhw8IUy-",
        "outputId": "b7b63692-8532-4568-d030-75875df5d2c2"
      },
      "source": [
        "!pip3 freeze"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "absl-py==0.12.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.1.0\n",
            "appdirs==1.4.4\n",
            "argcomplete==1.12.3\n",
            "argon2-cffi==21.1.0\n",
            "arviz==0.11.4\n",
            "astor==0.8.1\n",
            "astropy==4.3.1\n",
            "astunparse==1.6.3\n",
            "atari-py==0.2.9\n",
            "atomicwrites==1.4.0\n",
            "attrs==21.2.0\n",
            "audioread==2.1.9\n",
            "autograd==1.3\n",
            "Babel==2.9.1\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==4.1.0\n",
            "blis==0.4.1\n",
            "bokeh==2.3.3\n",
            "Bottleneck==1.3.2\n",
            "branca==0.4.2\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.10\n",
            "cached-property==1.5.2\n",
            "cachetools==4.2.4\n",
            "catalogue==1.0.0\n",
            "certifi==2021.10.8\n",
            "cffi==1.15.0\n",
            "cftime==1.5.1.1\n",
            "chardet==3.0.4\n",
            "charset-normalizer==2.0.7\n",
            "click==7.1.2\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.12.0\n",
            "cmdstanpy==0.9.5\n",
            "colorcet==2.0.6\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.3.2\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cvxopt==1.2.7\n",
            "cvxpy==1.0.31\n",
            "cycler==0.11.0\n",
            "cymem==2.0.6\n",
            "Cython==0.29.24\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "datascience==0.10.6\n",
            "debugpy==1.0.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "descartes==1.1.0\n",
            "dill==0.3.4\n",
            "distributed==1.25.3\n",
            "dlib @ file:///dlib-19.18.0-cp37-cp37m-linux_x86_64.whl\n",
            "dm-tree==0.1.6\n",
            "docopt==0.6.2\n",
            "docutils==0.17.1\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.290\n",
            "easydict==1.9\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm @ https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz\n",
            "entrypoints==0.3\n",
            "ephem==4.1\n",
            "et-xmlfile==1.1.0\n",
            "fa2==0.3.5\n",
            "fastai==1.0.61\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.8\n",
            "fbprophet==0.7.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.4.0\n",
            "firebase-admin==4.4.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.4\n",
            "flatbuffers==2.0\n",
            "folium==0.8.3\n",
            "fonttools==4.28.1\n",
            "future==0.16.0\n",
            "gast==0.4.0\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.52\n",
            "geopy==1.17.0\n",
            "gin-config==0.5.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.26.3\n",
            "google-api-python-client==1.12.8\n",
            "google-auth==1.35.0\n",
            "google-auth-httplib2==0.0.4\n",
            "google-auth-oauthlib==0.4.6\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-bigquery-storage==1.1.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.7.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab @ file:///colabtools/dist/google-colab-1.0.0.tar.gz\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.53.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==1.1.2\n",
            "grpcio==1.42.0\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.17.3\n",
            "h5py==3.1.0\n",
            "HeapDict==1.0.1\n",
            "hijri-converter==2.2.2\n",
            "holidays==0.10.5.2\n",
            "holoviews==1.14.6\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.10\n",
            "imageio==2.4.1\n",
            "imagesize==1.3.0\n",
            "imbalanced-learn==0.8.1\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==4.8.2\n",
            "importlib-resources==5.4.0\n",
            "imutils==0.5.4\n",
            "inflect==2.1.0\n",
            "iniconfig==1.1.1\n",
            "intel-openmp==2021.4.0\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.10.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.6.5\n",
            "itsdangerous==1.1.0\n",
            "jax==0.2.25\n",
            "jaxlib @ https://storage.googleapis.com/jax-releases/cuda11/jaxlib-0.1.74+cuda11.cudnn805-cp37-none-manylinux2010_x86_64.whl\n",
            "jdcal==1.4.1\n",
            "jedi==0.18.1\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.3\n",
            "joblib==1.1.0\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.5\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.9.1\n",
            "jupyterlab-pygments==0.1.2\n",
            "jupyterlab-widgets==1.0.2\n",
            "kaggle==1.5.12\n",
            "kapre==0.3.6\n",
            "keras==2.7.0\n",
            "Keras-Preprocessing==1.1.2\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.3.2\n",
            "korean-lunar-calendar==0.2.1\n",
            "libclang==12.0.0\n",
            "librosa==0.8.1\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.34.0\n",
            "lmdb==0.99\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.3.6\n",
            "MarkupSafe==2.0.1\n",
            "matplotlib==3.2.2\n",
            "matplotlib-inline==0.1.3\n",
            "matplotlib-venn==0.11.6\n",
            "missingno==0.5.0\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.11.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.2.1\n",
            "msgpack==1.0.2\n",
            "multiprocess==0.70.12.2\n",
            "multitasking==0.0.10\n",
            "murmurhash==1.0.6\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbclient==0.5.9\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.1.3\n",
            "nest-asyncio==1.5.1\n",
            "netCDF4==1.5.8\n",
            "networkx==2.6.3\n",
            "nibabel==3.0.2\n",
            "nltk==3.2.5\n",
            "notebook==5.3.1\n",
            "numba==0.51.2\n",
            "numexpr==2.7.3\n",
            "numpy==1.19.5\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.1\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.3.0\n",
            "osqp==0.6.2.post0\n",
            "packaging==21.3\n",
            "palettable==3.3.0\n",
            "pandas==1.1.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.13.3\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.5.0\n",
            "panel==0.12.1\n",
            "param==1.12.0\n",
            "parso==0.8.2\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.2\n",
            "pep517==0.12.0\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.1.2\n",
            "pip-tools==6.2.0\n",
            "plac==1.1.3\n",
            "plotly==4.4.1\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "pooch==1.5.2\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.1\n",
            "preshed==3.0.6\n",
            "prettytable==2.4.0\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.12.0\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.17.3\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.7.0\n",
            "py==1.11.0\n",
            "pyarrow==3.0.0\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.2\n",
            "pycparser==2.21\n",
            "pyct==0.4.8\n",
            "pydata-google-auth==1.2.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyerfa==2.0.0.1\n",
            "pyglet==1.5.0\n",
            "Pygments==2.6.1\n",
            "pygobject==3.26.1\n",
            "pymc3==3.11.4\n",
            "PyMeeus==0.5.11\n",
            "pymongo==3.12.1\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.5\n",
            "pyparsing==3.0.6\n",
            "pyrsistent==0.18.0\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==0.0.0\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.2\n",
            "python-louvain==0.15\n",
            "python-slugify==5.0.2\n",
            "python-utils==2.5.6\n",
            "pytz==2018.9\n",
            "pyviz-comms==2.1.0\n",
            "PyWavelets==1.2.0\n",
            "PyYAML==3.13\n",
            "pyzmq==22.3.0\n",
            "qdldl==0.1.5.post0\n",
            "qtconsole==5.2.0\n",
            "QtPy==1.11.2\n",
            "regex==2019.12.20\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "retrying==1.3.3\n",
            "rpy2==3.4.5\n",
            "rsa==4.7.2\n",
            "scikit-image==0.18.3\n",
            "scikit-learn==1.0.1\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.4\n",
            "seaborn==0.11.2\n",
            "semver==2.13.0\n",
            "Send2Trash==1.8.0\n",
            "setuptools-git==1.2\n",
            "setuptools-scm==6.3.2\n",
            "Shapely==1.8.0\n",
            "simplegeneric==0.8.1\n",
            "six==1.15.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==5.2.1\n",
            "snowballstemmer==2.2.0\n",
            "sortedcontainers==2.4.0\n",
            "SoundFile==0.10.3.post1\n",
            "spacy==2.2.4\n",
            "Sphinx==1.8.6\n",
            "sphinxcontrib-serializinghtml==1.1.5\n",
            "sphinxcontrib-websupport==1.2.4\n",
            "SQLAlchemy==1.4.27\n",
            "sqlparse==0.4.2\n",
            "srsly==1.0.5\n",
            "statsmodels==0.10.2\n",
            "sympy==1.7.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.9\n",
            "tblib==1.7.0\n",
            "tensorboard==2.7.0\n",
            "tensorboard-data-server==0.6.1\n",
            "tensorboard-plugin-wit==1.8.0\n",
            "tensorflow @ file:///tensorflow-2.7.0-cp37-cp37m-linux_x86_64.whl\n",
            "tensorflow-datasets==4.0.1\n",
            "tensorflow-estimator==2.7.0\n",
            "tensorflow-gcs-config==2.7.0\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-io-gcs-filesystem==0.22.0\n",
            "tensorflow-metadata==1.4.0\n",
            "tensorflow-probability==0.15.0\n",
            "termcolor==1.1.0\n",
            "terminado==0.12.1\n",
            "testpath==0.5.0\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "Theano-PyMC==1.1.2\n",
            "thinc==7.4.0\n",
            "threadpoolctl==3.0.0\n",
            "tifffile==2021.11.2\n",
            "toml==0.10.2\n",
            "tomli==1.2.2\n",
            "toolz==0.11.2\n",
            "torch @ https://download.pytorch.org/whl/cu111/torch-1.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
            "torchaudio @ https://download.pytorch.org/whl/cu111/torchaudio-0.10.0%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.11.0\n",
            "torchvision @ https://download.pytorch.org/whl/cu111/torchvision-0.11.1%2Bcu111-cp37-cp37m-linux_x86_64.whl\n",
            "tornado==5.1.1\n",
            "tqdm==4.62.3\n",
            "traitlets==5.1.1\n",
            "tweepy==3.10.0\n",
            "typeguard==2.7.1\n",
            "typing-extensions==3.10.0.2\n",
            "tzlocal==1.5.1\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.9.0\n",
            "wasabi==0.8.2\n",
            "wcwidth==0.2.5\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.1\n",
            "widgetsnbextension==3.5.2\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.13.3\n",
            "xarray==0.18.2\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==1.3.post1\n",
            "zict==2.0.0\n",
            "zipp==3.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpAwXDqfIoc_"
      },
      "source": [
        "from pip._internal.utils.misc import get_installed_distributions\n",
        "import sys\n",
        "#import numpy as np # imported to test whether numpy shows up, which it does!\n",
        "\n",
        "def get_imported_packages():\n",
        "    p = get_installed_distributions()\n",
        "    p = {package.key:package.version for package in p}\n",
        "\n",
        "    imported_modules = set(sys.modules.keys())\n",
        "    \n",
        "    imported_modules.remove('pip')\n",
        "\n",
        "    modules = [(m, p[m]) for m in imported_modules if p.get(m, False)]\n",
        "\n",
        "    return modules\n",
        "\n",
        "\n",
        "def generate_requirements(filepath:str, modules):\n",
        "    with open(filepath, 'w') as f:\n",
        "        for module, version in modules:\n",
        "            f.write(f\"{module}=={version}\\n\")\n",
        "\n",
        "\n",
        "generate_requirements('requirements.txt', get_imported_packages())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JQZ7MSbkIoVq",
        "outputId": "e02fc359-a016-4a2a-9eea-ef2ab9bb958a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.7.0'"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    }
  ]
}