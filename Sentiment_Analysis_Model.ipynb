{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment Analysis Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMa9zh91kqO2bqyzh671Sye",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Saadkhalid913/ML-Practice/blob/main/Sentiment_Analysis_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKxm39eiA6Uj",
        "outputId": "cfc7af37-ca47-4638-a6cb-fc3c45ba3d91"
      },
      "source": [
        "import numpy as np\n",
        "import nltk \n",
        "import tensorflow as tf \n",
        "import pandas as pd \n",
        "nltk.download(\"stopwords\")\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "import sklearn \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, Normalizer, OneHotEncoder, LabelEncoder \n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3Nh62HyBPe_"
      },
      "source": [
        "# segmenting and parsing data\n",
        "\n",
        "data = []\n",
        "with open(\"./data.txt\", \"r\") as f:\n",
        "  datapoints = f.read().split(\"\\n\")\n",
        "  for datapoint in datapoints:\n",
        "    sentence, emotion = datapoint.split(\";\")\n",
        "    data.append([sentence, emotion])\n",
        "\n",
        "data = np.array(data)\n",
        "\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWrPswiFCV-J"
      },
      "source": [
        "import re\n",
        "\n",
        "\n",
        "# defining utility functions \n",
        "ps = PorterStemmer()\n",
        "def replace_not_alphabetical_chars(s: str):\n",
        "  return re.sub(\"[^a-zA-Z]\", \" \", s)\n",
        "def SplitSentence(s: str):\n",
        "  s = s.lower()\n",
        "  s = s.split()\n",
        "  return s \n",
        "def GetStopwords():\n",
        "  words = stopwords.words(\"english\")\n",
        "  words.remove(\"not\")\n",
        "  return words\n",
        "def GetStem(word: str) -> str:\n",
        "  global ps \n",
        "  return ps.stem(word)\n"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-UrOzzEO6UX"
      },
      "source": [
        "EnglishStopwords = GetStopwords()"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgJCR0e-OXDd"
      },
      "source": [
        "# pre-processing data \n",
        "\n",
        "sentences = []\n",
        "for datapoint in data:\n",
        "  sentence, emotion = datapoint\n",
        "  sentence = replace_not_alphabetical_chars(sentence)\n",
        "  sentence = SplitSentence(sentence)\n",
        "  sentence = [GetStem(word) for word in sentence if word not in set(EnglishStopwords)]\n",
        "  sentence = \" \".join(sentence)\n",
        "  sentences.append(sentence)\n"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZczsO6-xQXKD"
      },
      "source": [
        "# Vectorizing words \n",
        "CV = CountVectorizer(max_features=1500)\n",
        "x = CV.fit_transform(sentences).toarray()"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fahfbF1S6lA",
        "outputId": "2ca754f9-9775-4c06-9d46-133fb33990e9"
      },
      "source": [
        "y[: 10]"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['sadness'],\n",
              "       ['sadness'],\n",
              "       ['sadness'],\n",
              "       ['joy'],\n",
              "       ['sadness'],\n",
              "       ['fear'],\n",
              "       ['anger'],\n",
              "       ['joy'],\n",
              "       ['joy'],\n",
              "       ['anger']], dtype='<U296')"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s2h2IzUsSGVG",
        "outputId": "f9e8a350-5c64-4cc8-d602-5b1569deddf5"
      },
      "source": [
        "# Encoding Y (getting classes)\n",
        "encoder = LabelEncoder()\n",
        "labels = encoder.fit_transform(y.flatten())\n",
        "classes = encoder.classes_"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4 4 4 ... 2 2 1]\n",
            "['anger' 'fear' 'joy' 'love' 'sadness' 'surprise']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAxxszVWSDmi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}